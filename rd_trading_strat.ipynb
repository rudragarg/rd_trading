{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R&D Trading Strategy\n",
    "## Rudraksh Garg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** All final results are at the bottom of the notebook. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Data processing libraries: \n",
    "\n",
    "- pandas\n",
    "- numpy\n",
    "\n",
    "Datetime calculations: \n",
    "- dateutil\n",
    "\n",
    "Runtime Output: \n",
    "- warnings\n",
    "\n",
    "Regressions: \n",
    "- statsmodel\n",
    "\n",
    "Sharpe Ratio Calculation: \n",
    "- math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Functions\n",
    "\n",
    "Below are functions that are used to gather, clean, and process data as inputs for backtesting. There are functions that process the monthly stock returns and other functions that process company R&D expenses. This section of functions also calculate the variables that will be used to create the quintiles that will be used to construct the long-short portfolio and calculate the effectiveness of the strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stocks_data(file = \"data/stocks.csv\"):\n",
    "    '''\n",
    "    Get stock monthly return and shares outstanding\n",
    "        Parameters:\n",
    "                file (string): file path\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): stock data \n",
    "    '''\n",
    "    return pd.read_csv(file)\n",
    "\n",
    "def clean_stock_data(stocks):\n",
    "    '''\n",
    "    Prepares stock data\n",
    "        Parameters:\n",
    "                stocks (DateFrame): stock data\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): cleaned stock data \n",
    "    '''\n",
    "    # convert to datetime\n",
    "    stocks[\"datadate\"] = pd.to_datetime(stocks[\"datadate\"])\n",
    "    \n",
    "    # Quarterly to monthly number of shares outstanding\n",
    "    stocks = stocks.sort_values(by=['LPERMNO', \"datadate\"])\n",
    "    stocks[\"cshoq\"] = stocks.groupby(\"tic\")[\"cshoq\"].fillna(method='ffill')\n",
    "    \n",
    "    # Remove 6000-6999 sic\n",
    "    stocks = stocks[(stocks[\"sic\"] <= 6000) | (stocks[\"sic\"] > 6999)]\n",
    "    \n",
    "    # Keep exchange code 11-19\n",
    "    stocks = stocks[(stocks[\"exchg\"] >= 11) & (stocks[\"exchg\"] <= 19)]\n",
    "\n",
    "    # Remove unreasonably high returns\n",
    "    stocks = stocks[(stocks[\"trt1m\"] < 500)]\n",
    "\n",
    "    # Remove impossible returns\n",
    "    stocks = stocks[(stocks[\"trt1m\"] > -100)]\n",
    "\n",
    "    # Remove stocks that have 0 or negative market cap\n",
    "    stocks = stocks[(stocks[\"cshoq\"] > 0)]\n",
    "\n",
    "    # If price is missing, make it nan\n",
    "    stocks[\"prccm\"] = stocks[\"prccm\"].replace({0:np.nan})\n",
    "\n",
    "    # Remove records that have misssing shares outstanding or price\n",
    "    stocks = stocks.dropna(subset=[\"cshoq\", \"prccm\"])\n",
    "\n",
    "    # Convert Market Cap out of millions\n",
    "    stocks[\"Market Cap\"] = stocks[\"prccm\"] * stocks[\"cshoq\"] * 1000000\n",
    "\n",
    "    # Ensure no misssing data\n",
    "    assert stocks.isna().sum().any() == False\n",
    "\n",
    "    # Get desired columns\n",
    "    stocks = stocks[[\"datadate\", \"GVKEY\", \"LPERMNO\", \"Market Cap\", \"trt1m\"]]\n",
    "\n",
    "    return stocks\n",
    "\n",
    "def save_gvkeys(stocks, column = \"GVKEY\"):\n",
    "    '''\n",
    "    Writes all gvkeys to file in format WRDS can read to pull fundamentals \n",
    "        Parameters:\n",
    "                stocks (DateFrame): stock data\n",
    "                column (string): column of gvkeys\n",
    "\n",
    "    '''\n",
    "    with open('gvkeys.txt', mode='wt', encoding='utf-8') as myfile:\n",
    "        myfile.write(\"\\n\".join([str(i) for i in stocks[column].unique().tolist()]))\n",
    "\n",
    "\n",
    "def get_fundamentals(file = \"data/fundamentals.csv\"):\n",
    "    '''\n",
    "    Get annual company fundamentals and their R&D Spending\n",
    "        Parameters:\n",
    "                file (string): file path\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): fundamentals data \n",
    "    '''\n",
    "    return pd.read_csv(file)[[\"datadate\",\"GVKEY\", \"LPERMNO\", \"xrd\"]]\n",
    "\n",
    "def clean_fundamentals(fundamentals):\n",
    "    '''\n",
    "    Prepares fundamentals data\n",
    "        Parameters:\n",
    "                fundamentals (DateFrame): fundamentals data\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): cleaned fundamentals data \n",
    "    '''\n",
    "    fundamentals[\"datadate\"] = pd.to_datetime(fundamentals[\"datadate\"])\n",
    "    fundamentals[\"xrd\"] = fundamentals[\"xrd\"].replace({np.nan:0})\n",
    "    return fundamentals\n",
    "\n",
    "def split_firms(fundamentals, debug = False):\n",
    "    '''\n",
    "    Separates rd firms and non-rd firms in 2 dataframes\n",
    "        Parameters:\n",
    "                fundamentals (DateFrame): fundamentals data\n",
    "                debug (boolean): print out debug statements of percent complete\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): all rd firms across time\n",
    "                (DateFrame): all non rd firms across time\n",
    "    '''\n",
    "    # Find continuous time period sets\n",
    "    ser_date = pd.to_datetime(fundamentals['datadate'])\n",
    "\n",
    "    # Find continuous rows that refer to the same GVKEY without breaks in time by years\n",
    "    ser_group = ((((ser_date.shift() + pd.DateOffset(years=1)) != ser_date) | \n",
    "                (fundamentals['GVKEY'].ne(fundamentals['GVKEY'].shift().bfill()).astype(int) != 0))\n",
    "                .cumsum())\n",
    "\n",
    "    g_df = fundamentals.groupby(ser_group) \n",
    "\n",
    "    # Get the list of continuous rows for each gvkey\n",
    "    df_periods = (g_df['GVKEY','datadate'].first() \n",
    "            .join(g_df['datadate'].last(),rsuffix='_') \n",
    "            .rename(columns={'datadate':'start','datadate_':'end'})) \n",
    "\n",
    "    # Find the length of the continuous time periods\n",
    "    df_periods[\"Period Length\"] = df_periods[\"end\"] - df_periods[\"start\"]\n",
    "    df_periods[\"Period Length\"] = df_periods[\"Period Length\"] / np.timedelta64(1, \"Y\")\n",
    "\n",
    "    # Fine rows, dates, gvkey sets that have less than 5 years\n",
    "    drop_periods = df_periods[df_periods[\"Period Length\"] < 4.999].reset_index(drop=True)\n",
    "\n",
    "    # Drop all indices that do not fall in a 5 year period\n",
    "    drop_idxs = []\n",
    "    num_rows = len(drop_periods)\n",
    "    for i, row, in drop_periods.iterrows():\n",
    "        gvkey = row[\"GVKEY\"]\n",
    "        start = row[\"start\"]\n",
    "        end = row[\"end\"]\n",
    "\n",
    "        drop_idxs = drop_idxs + list(fundamentals[(fundamentals[\"GVKEY\"] == gvkey) & (fundamentals[\"datadate\"] >= start) & (fundamentals[\"datadate\"] <= end)].index.values) #rd_firms\n",
    "        \n",
    "        if debug:\n",
    "            if i % 1000 == 0:\n",
    "                print(i/num_rows)\n",
    "\n",
    "    # Keep rows that have 5 or more years of R&D expenses\n",
    "    rd_firms = fundamentals.drop(drop_idxs)\n",
    "    # Rows that have less than 5 years of R&D expenses are non rd firms\n",
    "    non_rd_firms = fundamentals[fundamentals.index.isin(drop_idxs)]\n",
    "\n",
    "    # Find firms and dates that firm has not invested in RD for 5 years\n",
    "    temp = rd_firms.groupby('GVKEY')[\"xrd\"].rolling(5).sum() == 0\n",
    "    idxs = [i[1] for i in temp[temp].index]\n",
    "\n",
    "    # Ensure that all indices of 0 RD for 5 years are true indices\n",
    "    assert list(set(idxs) - set(list(rd_firms.index))) == []\n",
    "\n",
    "    # Add these 0 RD firms to the non rd firms data and remove from rd firms data\n",
    "    more_non_rd_firms = rd_firms.loc[idxs].sort_values(\"GVKEY\")\n",
    "    non_rd_firms = pd.concat([non_rd_firms, more_non_rd_firms])\n",
    "    rd_firms = rd_firms[~rd_firms.index.isin(idxs)]\n",
    "\n",
    "    # Convert RD expense out of millions\n",
    "    rd_firms[\"xrd\"] = rd_firms[\"xrd\"]  * 1000000\n",
    "\n",
    "    # NOTE: time shift 3 months because of delays in 10-K release\n",
    "    non_rd_firms[\"datadate\"] = non_rd_firms[\"datadate\"] + pd.Timedelta(days=90)\n",
    "    rd_firms[\"datadate\"] = rd_firms[\"datadate\"] + pd.Timedelta(days=90)\n",
    "\n",
    "    return rd_firms, non_rd_firms\n",
    "\n",
    "def calculate_rd_capital(rd_firms):\n",
    "    '''\n",
    "    Creates a column in rd firms data that reflects rd capital spend over 5 years\n",
    "        Parameters:\n",
    "                rd_firms (DateFrame): rd firms data\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): cleaned fundamentals data \n",
    "    '''\n",
    "    # RDC_t = 0.2(XRD_t-4) + 0.4(XRD_t-4) + 0.6(XRD_t-2) + 0.8(XRD_t-1) + XRD_t\n",
    "    weights = np.array([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "\n",
    "    rd_firms[\"R&D Capital\"] = rd_firms.groupby('GVKEY')[\"xrd\"].rolling(len(weights)).apply(lambda x: np.sum(weights*x)).reset_index()[[\"level_1\", \"xrd\"]].set_index(\"level_1\")\n",
    "    rd_firms.dropna(subset=\"R&D Capital\", inplace=True)\n",
    "    return rd_firms\n",
    "\n",
    "\n",
    "def get_market_cap(rd_firms, non_rd_firms, stocks):\n",
    "    '''\n",
    "    Merges monthly market cap information with annual fundamentals\n",
    "        Parameters:\n",
    "                rd_firms (DateFrame): rd firms data across time\n",
    "                non_rd_firms (DateFrame): non rd firms data across time\n",
    "                stocks (DataFrame): cleaned stocks data \n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): all rd firms across time with most recent market cap\n",
    "                (DateFrame): all non rd firms across time with most recent market cap\n",
    "    '''\n",
    "    # For later splitting\n",
    "    rd_firms[\"type\"] = \"rd\"\n",
    "    non_rd_firms[\"type\"] = \"non-rd\"\n",
    "\n",
    "    # Combine for one look loop\n",
    "    firms = pd.concat([rd_firms, non_rd_firms])\n",
    "\n",
    "    # Get most recent market cap for each firm at the time of their 10-k release\n",
    "    market_caps_dfs = []\n",
    "    #NOTE: When using LPERMNO, this merge takes over an hour....results are similar when using GVKEY\n",
    "    for GVKEY in firms[\"GVKEY\"].unique():\n",
    "        firm = firms[firms[\"GVKEY\"] == GVKEY].sort_values(\"datadate\")\n",
    "        stock_firm = stocks[stocks[\"GVKEY\"] == GVKEY].sort_values(\"datadate\")\n",
    "\n",
    "        # If market cap not available for current date, just use the most previous month market cap that has market cap data\n",
    "        mark_cap = pd.merge_asof(firm, stock_firm[[\"datadate\", \"Market Cap\"]], on=\"datadate\", allow_exact_matches=True, direction=\"backward\")\n",
    "        market_caps_dfs.append(mark_cap)\n",
    "    \n",
    "    firms = pd.concat(market_caps_dfs)\n",
    "\n",
    "    # Split type\n",
    "    rd_firms = firms[firms[\"type\"] == 'rd'].drop(\"type\", axis=1)\n",
    "    non_rd_firms = firms[firms[\"type\"] == 'non-rd'].drop(\"type\", axis=1)\n",
    "\n",
    "    return rd_firms, non_rd_firms\n",
    "\n",
    "def calculate_sorting_var(rd_firms):\n",
    "    '''\n",
    "    Create sorting column for rd firms that use rd capital and market cap\n",
    "        Parameters:\n",
    "                rd_firms (DateFrame): rd firms data across time with market cap\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): rd firms with sorting variable column\n",
    "    '''\n",
    "    # Normalize on market cap\n",
    "    rd_firms[\"R&D Capital/Market Cap\"] = rd_firms[\"R&D Capital\"] / rd_firms[\"Market Cap\"]\n",
    "    return rd_firms\n",
    "\n",
    "\n",
    "def get_most_recent_report(rd_firms, non_rd_firms, reconst_month = 4, reconst_day = 1):\n",
    "    '''\n",
    "    Use most recent fundamentals report in a year if there is more than one\n",
    "        Parameters:\n",
    "                rd_firms (DateFrame): rd firms data across time\n",
    "                non_rd_firms (DateFrame): non rd firms data across time\n",
    "                reconst_month (int): month number that portfolio will be reconstituted\n",
    "                reconst_day (int): day number that portfolio will be reconstituted\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): all rd firms across time with most recent 10-K report\n",
    "                (DateFrame): all non rd firms across time with most recent 10-K report\n",
    "    '''\n",
    "    # Get the year that will use this sorting variable\n",
    "    rd_firms[\"year\"] = [i.year+1 if i >= pd.Timestamp(year=i.year, month=reconst_month, day=reconst_day) else i.year for i in rd_firms[\"datadate\"]]\n",
    "    non_rd_firms[\"year\"] = [i.year+1 if i >= pd.Timestamp(year=i.year, month=reconst_month, day=reconst_day) else i.year for i in non_rd_firms[\"datadate\"]]\n",
    "    \n",
    "    # Get the most recent by keeping last\n",
    "    rd_firms = rd_firms.drop_duplicates([\"year\", \"GVKEY\"], keep=\"last\")\n",
    "    non_rd_firms = non_rd_firms.drop_duplicates([\"year\", \"GVKEY\"], keep=\"last\")\n",
    "    \n",
    "    # Confirm that there is only one report per year for each firm\n",
    "    for year in rd_firms[\"year\"].unique():\n",
    "        assert (rd_firms[rd_firms[\"year\"] == year][\"GVKEY\"].value_counts() == 1).all() == True\n",
    "        assert (non_rd_firms[non_rd_firms[\"year\"] == year][\"GVKEY\"].value_counts() == 1).all() == True\n",
    "\n",
    "    return rd_firms, non_rd_firms\n",
    "\n",
    "def remove_sorting_var_outliers(rd_firms, threshold = .99):\n",
    "    '''\n",
    "    Remove unreasonably high sorting var where the capital invested is much higher than the market cap\n",
    "        Parameters:\n",
    "                rd_firms (DateFrame): rd firms data across time with sorting variable\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): all rd firms across time with cleaned outliers\n",
    "    '''\n",
    "    rd_firms = rd_firms[rd_firms[\"R&D Capital/Market Cap\"] < rd_firms[\"R&D Capital/Market Cap\"].quantile(threshold)]\n",
    "    return rd_firms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtest and Get Portfolio Returns\n",
    "\n",
    "Below are functions that are used to bin stocks based on the sorting variable, create the equal weighted and value weighted portfolio. There are also functions that process the risk free rate data and use that in order to calculate excess return of the portfolio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bins(rd_firms, non_rd_firms, current_year = 1981, max_year=2022, month_reconst=4, day_reconst=1):\n",
    "    '''\n",
    "    Bin the sorting variable into 5 buckets from lowest to highest\n",
    "        Parameters:\n",
    "                rd_firms (DateFrame): rd firms data across time with sorting variable\n",
    "                non_rd_firms (DateFrame): rd firms data across time with sorting variable\n",
    "                current_year (int): earliest year of backtest\n",
    "                max_year (int): most recent year of backtest\n",
    "                reconst_month (int): month number that portfolio will be reconstituted\n",
    "                reconst_day (int): day number that portfolio will be reconstituted\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): data for each year and it's respective companies in each bin\n",
    "    '''\n",
    "\n",
    "    dates = []\n",
    "\n",
    "    H = []\n",
    "    four = []\n",
    "    three = []\n",
    "    two = []\n",
    "    L = []\n",
    "    non_rd = []\n",
    "\n",
    "    number_bins = 5\n",
    "    labels = [\"L\", \"2\", \"3\", \"4\", \"H\"]\n",
    "\n",
    "    # Iterate through each year\n",
    "    while current_year <= max_year:\n",
    "        \n",
    "        # Get all rd and non_rd firms of that year\n",
    "        current_reconst_firms = rd_firms[rd_firms[\"year\"] == current_year]\n",
    "        current_reconst_firms_non_rd = non_rd_firms[non_rd_firms[\"year\"] == current_year]\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        switch = False\n",
    "        \n",
    "        # If there are rd firms that year\n",
    "        if current_reconst_firms.shape[0] > 0:\n",
    "            # Bin firms\n",
    "            current_reconst_firms[\"R&D Bins\"] = pd.qcut(current_reconst_firms[\"R&D Capital/Market Cap\"], number_bins, labels=labels)\n",
    "            # Add to lists for columns\n",
    "            H.append(current_reconst_firms[current_reconst_firms[\"R&D Bins\"]==\"H\"][\"GVKEY\"].values)\n",
    "            four.append(current_reconst_firms[current_reconst_firms[\"R&D Bins\"]==\"4\"][\"GVKEY\"].values)\n",
    "            three.append(current_reconst_firms[current_reconst_firms[\"R&D Bins\"]==\"3\"][\"GVKEY\"].values)\n",
    "            two.append(current_reconst_firms[current_reconst_firms[\"R&D Bins\"]==\"2\"][\"GVKEY\"].values)\n",
    "            L.append(current_reconst_firms[current_reconst_firms[\"R&D Bins\"]==\"L\"][\"GVKEY\"].values)\n",
    "            switch = True\n",
    "            dates.append(pd.Timestamp(year=current_year, month=month_reconst, day=day_reconst))\n",
    "        \n",
    "            # Do the same for non rd firms\n",
    "            if current_reconst_firms_non_rd.shape[0] > 0:\n",
    "                non_rd.append(current_reconst_firms_non_rd[\"GVKEY\"].values)\n",
    "                \n",
    "\n",
    "\n",
    "        current_year += 1\n",
    "\n",
    "    # Create table\n",
    "    tic_bins = pd.DataFrame()\n",
    "\n",
    "    tic_bins[\"date\"] = dates\n",
    "    tic_bins[\"L\"] = L\n",
    "    tic_bins[\"2\"] = two\n",
    "    tic_bins[\"3\"] = three\n",
    "    tic_bins[\"4\"] = four\n",
    "    tic_bins[\"H\"] = H\n",
    "    tic_bins[\"Non R&D\"] = non_rd\n",
    "\n",
    "    return tic_bins\n",
    "\n",
    "def get_rf_rate_monthly(stocks, file = \"data/F-F_Research_Data_Factors_monthly.CSV\"):\n",
    "    '''\n",
    "    Create a series of the risk free rate every month\n",
    "        Parameters:\n",
    "                stocks (DateFrame): all stock data to get dates\n",
    "                file (DateFrame): file path to risk free data\n",
    "              \n",
    "\n",
    "        Returns:\n",
    "                (Series): risk free rate each month in past\n",
    "    '''\n",
    "\n",
    "    # Pull the Fama French data which has the risk free rate per month in it\n",
    "    rf = pd.read_csv(file).rename({\"Unnamed: 0\": \"datadate\"}, axis=1)[[\"datadate\", \"RF\"]]\n",
    "\n",
    "    # Convert to datetime\n",
    "    rf[\"datadate\"] = pd.to_datetime(rf[\"datadate\"], format=\"%Y%m\")\n",
    "    \n",
    "    # Remove copies and any missing months\n",
    "    rf.drop_duplicates(subset=\"datadate\", inplace=True, keep=\"last\")\n",
    "    rf.dropna(inplace=True)\n",
    "    \n",
    "    # Get most recent rf for a month if it is not available for all months in analysis\n",
    "    rf = rf.sort_values(\"datadate\")\n",
    "    rf = pd.merge_asof(stocks.sort_values(\"datadate\"), rf, direction=\"backward\", on=\"datadate\")[[\"datadate\",\"RF\"]]\n",
    "    rf = rf.dropna()\n",
    "    # Create a series\n",
    "    rf = rf.drop_duplicates().set_index(\"datadate\").squeeze()\n",
    "    return rf\n",
    "\n",
    "\n",
    "def get_equal_weighted_portfolio(tic_bins, stocks, rf):\n",
    "    '''\n",
    "    Back test a portfolio where are holdings are invested in equal proportions\n",
    "        Parameters:\n",
    "                tic_bins (DateFrame): data of each year and companies inside of each bin \n",
    "                stocks (DateFrame): data of each stock return over time\n",
    "                rf (Series): data of risk free rate every month\n",
    "            \n",
    "\n",
    "        Returns:\n",
    "                (DataFrame): Returns of each month for each bin\n",
    "    '''\n",
    "    equally_weighted_month_returns = []\n",
    "    # For each year\n",
    "    for i, row in tic_bins.iterrows():\n",
    "        # Get the bins\n",
    "        L, two, three, four, H, non = row[\"L\"], row[\"2\"], row[\"3\"], row[\"4\"], row[\"H\"], row[\"Non R&D\"]\n",
    "        starting_date = row[\"date\"]\n",
    "        ending_date = starting_date + relativedelta(years=1)\n",
    "\n",
    "        # Get market snapshot of that year\n",
    "        market = stocks[(stocks[\"datadate\"] >= starting_date) & (stocks[\"datadate\"] < ending_date)].sort_values(\"datadate\")\n",
    "\n",
    "        return_row = [starting_date]\n",
    "        binned_month_returns = []\n",
    "\n",
    "        # For each bin\n",
    "        for bin in [L, two, three, four, H, non]:\n",
    "\n",
    "            # Find those stocks in that bin in the market snapshot\n",
    "            bin_df = market[market['GVKEY'].isin(bin)]\n",
    "            \n",
    "            # Get the mean return per month\n",
    "            monthly_avg_return = bin_df.groupby(\"datadate\").mean()[\"trt1m\"]\n",
    "        \n",
    "            # Calculate the excess return with respect to the risk free rate\n",
    "            monthly_avg_return = monthly_avg_return.sub(rf).dropna()\n",
    "            binned_month_returns.append(monthly_avg_return)\n",
    "        \n",
    "        equally_weighted_month_returns.append(pd.concat(binned_month_returns, axis=1))\n",
    "    \n",
    "    equal_weighted_monthly_returns_df = pd.concat(equally_weighted_month_returns)\n",
    "    equal_weighted_monthly_returns_df.columns = ['L', '2', '3', '4', 'H', \"Non R&D\"]\n",
    "    \n",
    "    return equal_weighted_monthly_returns_df\n",
    "\n",
    "\n",
    "def _get_weights(market, bin, date, unknown_market_cap_zero_weight):\n",
    "    '''\n",
    "    Helper function to construct value weighted portfolio; looks at past month market cap to determine the proportion invested of this month\n",
    "        Parameters:\n",
    "                market (DateFrame): Snapshot of the market in that year\n",
    "                bin (DateFrame): the quintile that is currently being studied\n",
    "                date (Series): current month being calculated; first of the month\n",
    "            \n",
    "\n",
    "        Returns:\n",
    "                (dict): key=gvkey, value=weight for current month\n",
    "    '''\n",
    "    # Get the last month's market data\n",
    "    last_month = date - relativedelta(days=1)\n",
    "    last_month_stocks = market[(market[\"datadate\"] == last_month) & (market[\"GVKEY\"].isin(bin))]  \n",
    "    \n",
    "    # Set the default market cap if market cap not available last month\n",
    "    if unknown_market_cap_zero_weight:\n",
    "        default_market_cap = 0\n",
    "    else:\n",
    "        # Use a default market cap that can give equal weight with respect to number of stocks in bin like the equal weighted portfolio\n",
    "        default_market_cap = last_month_stocks[\"Market Cap\"].sum()/len(bin)\n",
    "    \n",
    "    # Find the stocks that have missing market caps last year\n",
    "    missing_gvkeys = list(set(bin)-set(last_month_stocks[\"GVKEY\"]))\n",
    "    # For each missing stock, set the default market cap\n",
    "    for missing_gvkey in missing_gvkeys:\n",
    "        add_row = {'datadate': date - relativedelta(days=1), 'GVKEY': missing_gvkey, \"LPERMNO\": np.nan, \"Market Cap\": default_market_cap, \"trt1m\":np.nan}\n",
    "        last_month_stocks = last_month_stocks.append(add_row, ignore_index = True)\n",
    "    \n",
    "    # Calculate the weight of each stock given their market cap\n",
    "    last_month_stocks[\"weight\"] = last_month_stocks[\"Market Cap\"] / last_month_stocks[\"Market Cap\"].sum()\n",
    "\n",
    "    try:\n",
    "        # Ensure that higher market cap stocks have higher weight\n",
    "        assert (last_month_stocks[\"Market Cap\"].sort_values().index == last_month_stocks[\"weight\"].sort_values().index).all() == True\n",
    "        # Ensure that all weights sum up to 1\n",
    "        assert last_month_stocks[\"weight\"].sum() > .999\n",
    "    \n",
    "    except AssertionError: \n",
    "        # if one of the check fail, run another check to see if equal values are misindexed\n",
    "        list1 = last_month_stocks[\"Market Cap\"].sort_values().index\n",
    "        list2 = last_month_stocks[\"weight\"].sort_values().index\n",
    "        out_of_order = [(list1[i], list2[i]) for i in range(len(list1)) if list1[i]!= list2[i]]\n",
    "        \n",
    "        \n",
    "        index = list(zip(*out_of_order))\n",
    "        df1 = last_month_stocks.iloc[list(index[0])]\n",
    "        df2 = last_month_stocks.iloc[list(index[1])]\n",
    "        # See if stocks had equal market cap and weight and were misindexed\n",
    "        if (df1[[\"Market Cap\", \"weight\"]].sort_values(\"Market Cap\").reset_index(drop=True).equals(df2[[\"Market Cap\", \"weight\"]].sort_values(\"Market Cap\").reset_index(drop=True))):\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            # ERROR\n",
    "            display(df1[[\"Market Cap\", \"weight\"]].sort_values(\"Market Cap\").reset_index(drop=True))\n",
    "            display(df2[[\"Market Cap\", \"weight\"]].sort_values(\"Market Cap\").reset_index(drop=True))\n",
    "            print(out_of_order)\n",
    "            print(last_month_stocks[\"weight\"].sum())\n",
    "\n",
    "            raise AssertionError(\"Weighting Issue\")\n",
    "        \n",
    "    return dict(zip(last_month_stocks[\"GVKEY\"], last_month_stocks[\"weight\"]))\n",
    "\n",
    "\n",
    "# NOTE: Could have used existing library functions to compute weighted average of returns but because of missing data, sanity checks, and debugging, I have explicitly rewrote the method\n",
    "def get_value_weighted_portfolio(tic_bins, stocks, rf, unknown_market_cap_zero_weight = False, debug = False):\n",
    "    '''\n",
    "    Back test a portfolio where are holdings are invested in proportions based on their previous month's market cap\n",
    "        Parameters:\n",
    "                tic_bins (DateFrame): data of each year and companies inside of each bin \n",
    "                stocks (DateFrame): data of each stock return over time\n",
    "                rf (Series): data of risk free rate every month\n",
    "                unknown_market_cap_zero_weight (bool): True if using zero weight for missing market cap; false if using equal weight\n",
    "                debug (bool): prints debug statements regarding progress\n",
    "            \n",
    "\n",
    "        Returns:\n",
    "                (DataFrame): Returns of each month for each bin\n",
    "    '''\n",
    "    \n",
    "    return_rows = []\n",
    "    value_weighted_month_returns = []\n",
    "    with warnings.catch_warnings():\n",
    "    \n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        for i, row in tic_bins.iterrows():\n",
    "            L, two, three, four, H, non = row[\"L\"], row[\"2\"], row[\"3\"], row[\"4\"], row[\"H\"], row[\"Non R&D\"]\n",
    "            starting_date = row[\"date\"]\n",
    "            if debug:\n",
    "                print(i/len(tic_bins))\n",
    "            ending_date = starting_date + relativedelta(years=1)\n",
    "\n",
    "\n",
    "            market = stocks[(stocks[\"datadate\"] >= starting_date - relativedelta(months=1)) & (stocks[\"datadate\"] < ending_date)].sort_values(\"datadate\")\n",
    "\n",
    "            return_row = [starting_date]\n",
    "            binned_month_returns = []\n",
    "            for bin in [L, two, three, four, H, non]:\n",
    "                current_month = starting_date\n",
    "                \n",
    "                return_dict = {}\n",
    "                while current_month < ending_date:\n",
    "                    return_weights = _get_weights(market, bin, current_month, unknown_market_cap_zero_weight)\n",
    "                    this_month_return = market[(market[\"datadate\"] == current_month + relativedelta(days=-1, months=1)) & (market[\"GVKEY\"].isin(bin))]\n",
    "                    this_month_return[\"weight\"] = this_month_return['GVKEY'].map(return_weights)\n",
    "                   \n",
    "                    total_return = (this_month_return[\"trt1m\"] * this_month_return[\"weight\"]).sum()\n",
    "                    \n",
    "                    return_dict[current_month + relativedelta(days=-1, months=1)] = total_return\n",
    "                    current_month += relativedelta(months=1)\n",
    "                weighted_returns = pd.Series(return_dict)\n",
    "                weighted_returns = weighted_returns.sub(rf).dropna()\n",
    "                binned_month_returns.append(weighted_returns)\n",
    "            \n",
    "            value_weighted_month_returns.append(pd.concat(binned_month_returns, axis=1))\n",
    "    \n",
    "    value_weighted_month_returns_df = pd.concat(value_weighted_month_returns)\n",
    "    value_weighted_month_returns_df.columns = ['L', '2', '3', '4', 'H', \"Non R&D\"]\n",
    "    return value_weighted_month_returns_df\n",
    "\n",
    "def get_results_table(monthly_returns):\n",
    "    '''\n",
    "    Create table that shows average monthly return for each time period\n",
    "        Parameters:\n",
    "               monthly_returns: returns of each month for each bin\n",
    "\n",
    "        Returns:\n",
    "                (DataFrame): average return of each month for each bin over time periods\n",
    "    '''\n",
    "    first_period = pd.Timestamp(year=1981, month=7, day=1)\n",
    "    mid_period = pd.Timestamp(year=1999, month=12, day=31)\n",
    "    last_period = pd.Timestamp(year=2012, month=12, day=31)\n",
    "    extra_period = pd.Timestamp(year=2021, month=12, day=31)\n",
    "\n",
    "\n",
    "    full_period = monthly_returns[(monthly_returns.index >= first_period) & (monthly_returns.index <= last_period)].mean()\n",
    "    pre_2000 = monthly_returns[(monthly_returns.index >= first_period) & (monthly_returns.index <= mid_period)].mean()\n",
    "    post_2000 = monthly_returns[(monthly_returns.index > mid_period) & (monthly_returns.index <= last_period)].mean()\n",
    "    extra = monthly_returns[(monthly_returns.index >= first_period) & (monthly_returns.index <= extra_period)].mean()\n",
    "    columns=['L', '2', '3', '4', 'H', 'Non R&D']\n",
    "\n",
    "\n",
    "    results = pd.DataFrame({c: pd.Series(dtype=\"float\") for c in columns})\n",
    "\n",
    "    results = results.append(full_period,ignore_index=True)\n",
    "    results = results.append(pre_2000,ignore_index=True)\n",
    "    results = results.append(post_2000,ignore_index=True)\n",
    "    results = results.append(extra,ignore_index=True)\n",
    "\n",
    "    results.index = [\"Full period\", \"Pre 2000\", \"Post 2000\", \"Full Through Dec 2021\"]\n",
    "\n",
    "    return results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long-Short Functions\n",
    "\n",
    "Below are functions that are used to test how well our strategy has done and if it produced a positive and significant alpha using regressions. There are also functions that compute the Sharpe ratio as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_fama_french_data(file = \"data/F-F_Research_Data_Factors_monthly.CSV\"):\n",
    "    '''\n",
    "    Get fama french factors\n",
    "        Parameters:\n",
    "                file (string): file path\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): factors data\n",
    "    '''\n",
    "    return pd.read_csv(file)\n",
    "\n",
    "def prep_regression(ff_factors_monthly, monthly_returns, last_period = pd.Timestamp(year=2012, month=12, day=31)):\n",
    "    '''\n",
    "    Clean data and prepare it for regressions\n",
    "        Parameters:\n",
    "                ff_factors_monthly (DataFrame): factor data\n",
    "                monthly_returns (DataFrame): monthly returns of each bin\n",
    "                last_period (Timestamp): end date of regression\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): factors data cleaned\n",
    "                (Series): High minus Low R&D returns\n",
    "    '''\n",
    "    # Beginning date of regression\n",
    "    first_period = pd.Timestamp(year=1981, month=7, day=1)\n",
    "\n",
    "    # Clean factor data\n",
    "    ff_factors_monthly.rename({\"Unnamed: 0\":\"Date\"}, axis=1, inplace=True)\n",
    "    ff_factors_monthly[\"Date\"] = pd.to_datetime(ff_factors_monthly[\"Date\"], format=\"%Y%m\")\n",
    "\n",
    "    # Get High R&D investment companies' return and minus them from Low R&D investment companies' return\n",
    "    monthly_returns[\"HmL\"] = monthly_returns[\"H\"] - monthly_returns[\"L\"]\n",
    "\n",
    "    # Get desired time frame\n",
    "    ff_factors_monthly = ff_factors_monthly[(ff_factors_monthly[\"Date\"] >= first_period) &(ff_factors_monthly[\"Date\"] <= last_period + relativedelta(days=1))]\n",
    "    \n",
    "    # Shift day back to match with monthly returns date\n",
    "    ff_factors_monthly[\"Date\"] = [i - relativedelta(days=1) for i in ff_factors_monthly[\"Date\"]]\n",
    "    \n",
    "    # Get desired time frame\n",
    "    HmL_rds = monthly_returns[(monthly_returns.index >= first_period )& (monthly_returns.index <= last_period)][\"HmL\"]\n",
    "\n",
    "    return ff_factors_monthly, HmL_rds\n",
    "\n",
    "def run_regression(ff_factors_monthly, HmL_rds, factors):\n",
    "    '''\n",
    "    Display regression results and summary\n",
    "        Parameters:\n",
    "                ff_factors_monthly (DataFrame): factor data\n",
    "                HmL_rds (DataFrame): High minus Low R&D returns\n",
    "                factors (list): factors that should be included in regression\n",
    "    '''\n",
    "    # Get features and target\n",
    "    X = ff_factors_monthly[factors]\n",
    "    y = HmL_rds.copy()\n",
    "\n",
    "\n",
    "    # Match dates that are in both features and target\n",
    "    remove_dates_X = list(set(ff_factors_monthly[\"Date\"])- set(y.index))\n",
    "\n",
    "    X_df = ff_factors_monthly[~ff_factors_monthly[\"Date\"].isin(remove_dates_X)]\n",
    "\n",
    "    # Ensure that all dates in target are in features\n",
    "    assert list(set(y.index) - set(X_df[\"Date\"])) == []\n",
    "  \n",
    "\n",
    "    # Run regression\n",
    "    X = X_df[factors]\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "    X_sm = sm.add_constant(X)\n",
    "    model = sm.OLS(y,X_sm)\n",
    "    results = model.fit()\n",
    "    \n",
    "    \n",
    "    print(\"alpha: \", round(results.params[0], 2))\n",
    "    print(\"t-stat: \", round(results.tvalues[0], 3))\n",
    "\n",
    "\n",
    "def calculate_sharpe_ratio(y):\n",
    "    '''\n",
    "    Calculate the portfolio's sharpe ratio\n",
    "        Parameters:\n",
    "                y (Series): High minus low R&D returns\n",
    "        Returns:\n",
    "                (float): Calculated Sharpe Ratio\n",
    "    '''\n",
    "    rp = y.mean()\n",
    "    std_rp = y.std()\n",
    "\n",
    "    # Annual Sharpe Ratio\n",
    "    sharpe_ratio = (rp)/std_rp * math.sqrt(12)\n",
    "    return round(sharpe_ratio,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Large Cap Function\n",
    "\n",
    "Below is a function that removes the 1000 large cap stocks from both the R&D firms and the non R&D firms as large cap stocks can significantly influence a value weighted portfolio more than small cap stocks which could significantly impact results. We can test results without these stock as well using this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_top_1000(rd_firms, non_rd_firms):\n",
    "    '''\n",
    "    Remove top 1000 market cap firms from rd firms and non rd firms\n",
    "        Parameters:\n",
    "                rd_firms (DataFrame): All rd firms data\n",
    "                non_rd_firms (DataFrame): All non rd firms data\n",
    "\n",
    "        Returns:\n",
    "                (DataFrame): rd firms data without largest 1000\n",
    "                (DataFrame): non rd firms data without largest 1000\n",
    "    '''\n",
    "    # Sort by Market Cap for rd firms\n",
    "    temp_1 = rd_firms.reset_index(drop=True).sort_values('Market Cap',ascending = False)\n",
    "    # For each year get the top 1000 firms\n",
    "    temp_2 = temp_1.groupby(\"year\").head(1000).sort_values(\"year\") \n",
    "    # Removes these top 1000 \n",
    "    removed_top_rd = temp_1[~temp_1.index.isin(temp_2.index)]\n",
    "\n",
    "    # Do the same for non rd firms\n",
    "    temp_1 = non_rd_firms.reset_index(drop=True).sort_values('Market Cap',ascending = False)\n",
    "    temp_2 = temp_1.groupby(\"year\").head(1000).sort_values(\"year\")  \n",
    "    removed_top_non_rd = temp_1[~temp_1.index.isin(temp_2.index)]\n",
    "\n",
    "    return removed_top_rd, removed_top_non_rd    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper Functions\n",
    "\n",
    "Functions below run all functions above in the correct sequential order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \n",
    "    '''\n",
    "    Wraps all data gathering, cleaning, and splitting functions\n",
    "        Returns:\n",
    "                (DataFrame): rd firms data\n",
    "                (DataFrame): non rd firms data\n",
    "                (DataFrame): stock data\n",
    "    '''\n",
    "    print(\"Getting stock data\")\n",
    "    stocks = get_stocks_data()\n",
    "    stocks = clean_stock_data(stocks)\n",
    "    save_gvkeys(stocks)\n",
    "\n",
    "    print(\"Getting Fundamentals\")\n",
    "    fundamentals = get_fundamentals()\n",
    "    fundamentals = clean_fundamentals(fundamentals)\n",
    "\n",
    "    print(\"Splitting Firms into RD and non RD\")\n",
    "    rd_firms, non_rd_firms = split_firms(fundamentals)\n",
    "    rd_firms, non_rd_firms = get_market_cap(rd_firms, non_rd_firms, stocks)\n",
    "\n",
    "    print(\"Calculating RD Capital / Market Cap\")\n",
    "    rd_firms = calculate_rd_capital(rd_firms)\n",
    "    rd_firms = calculate_sorting_var(rd_firms)\n",
    "\n",
    "    print(\"Finding most recent report each year\")\n",
    "    rd_firms, non_rd_firms = get_most_recent_report(rd_firms, non_rd_firms)\n",
    "\n",
    "    print(\"Removing outliers\")\n",
    "    rd_firms = remove_sorting_var_outliers(rd_firms)\n",
    "\n",
    "    return rd_firms, non_rd_firms, stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression_results(monthly_returns, last_period = pd.Timestamp(year=2012, month=12, day=31)):\n",
    "    '''\n",
    "    Wraps all regression functions\n",
    "     Parameters:\n",
    "                monthly_returns (DataFrame): Monthly returns for each bin\n",
    "                last_period (Timestamp): end date of regression\n",
    "\n",
    "        Returns:\n",
    "                (Series): High minus Low R&D returns\n",
    "    '''\n",
    "\n",
    "    ff_factors_monthly = get_fama_french_data()\n",
    "    ff_factors_monthly, HmL_rds = prep_regression(ff_factors_monthly, monthly_returns, last_period)\n",
    "    \n",
    "    print(\"\\nCAPM Regression\")\n",
    "    run_regression(ff_factors_monthly, HmL_rds, [\"Mkt-RF\"])\n",
    "    \n",
    "    print(\"\\nFama French Regression Results\")\n",
    "    run_regression(ff_factors_monthly, HmL_rds, [\"Mkt-RF\", \"SMB\", \"HML\"])\n",
    "    \n",
    "    return HmL_rds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_equal_portfolio(rd_firms, non_rd_firms, stocks):\n",
    "    \n",
    "    '''\n",
    "    Wraps all equal portfolio functions\n",
    "     Parameters:\n",
    "                rd_firms (DataFrame): rd firms data\n",
    "                non_rd_firms (DataFrame): non rd firms data\n",
    "                stocks (DataFrame): stock data\n",
    "\n",
    "    '''\n",
    "\n",
    "    tic_bins = get_bins(rd_firms, non_rd_firms)\n",
    "    rf = get_rf_rate_monthly(stocks)\n",
    "    monthly_returns = get_equal_weighted_portfolio(tic_bins, stocks, rf)\n",
    "    results = get_results_table(monthly_returns)\n",
    "    \n",
    "    print(\"\\nAverage Monthly Return foe Equal Weighted Portfolio\")\n",
    "    display(results)\n",
    "    \n",
    "    print(\"\\nRegression Results for 1981-2012\")\n",
    "    HmL_rds = get_regression_results(monthly_returns, last_period = pd.Timestamp(year=2012, month=12, day=31))\n",
    "    \n",
    "    print(\"\\nSharpe Ratio (1981-2012):\", calculate_sharpe_ratio(HmL_rds))\n",
    "\n",
    "    \n",
    "    print(\"\\nRegression Results for 1981-2021\")\n",
    "    HmL_rds = get_regression_results(monthly_returns, last_period = pd.Timestamp(year=2021, month=12, day=31))\n",
    "     \n",
    "    print(\"\\nSharpe Ratio (1981-2021):\", calculate_sharpe_ratio(HmL_rds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_value_portfolio(rd_firms, non_rd_firms, stocks, remove_top_1000_stocks = False, unknown_market_cap_zero_weight = True):\n",
    "    '''\n",
    "    Wraps all equal portfolio functions\n",
    "     Parameters:\n",
    "                rd_firms (DataFrame): rd firms data\n",
    "                non_rd_firms (DataFrame): non rd firms data\n",
    "                stocks (DataFrame): stock data\n",
    "                remove_top_1000_stocks (boolean): True if need to remove largest 1000\n",
    "                unknown_market_cap_zero_weight (boolean): True if setting 0 weight to unavailable market cap in previous month\n",
    "\n",
    "    '''\n",
    "    if remove_top_1000_stocks:\n",
    "        rd_firms, non_rd_firms = remove_top_1000(rd_firms, non_rd_firms)\n",
    "\n",
    "    tic_bins = get_bins(rd_firms, non_rd_firms)\n",
    "    rf = get_rf_rate_monthly(stocks)\n",
    "    monthly_returns = get_value_weighted_portfolio(tic_bins[tic_bins[\"date\"] <= \"2021-12-21\"], stocks, rf, unknown_market_cap_zero_weight)\n",
    "    results = get_results_table(monthly_returns)\n",
    "    \n",
    "    if remove_top_1000_stocks:\n",
    "        print(\"\\nAverage Monthly Return for Value Weighted Portfolio without Top 1000\")\n",
    "    else:\n",
    "        print(\"\\nAverage Monthly Return for Value Weighted Portfolio\")\n",
    "    display(results)\n",
    "    \n",
    "    print(\"\\nRegression Results for 1981-2012\")\n",
    "    HmL_rds = get_regression_results(monthly_returns, last_period = pd.Timestamp(year=2012, month=12, day=31))\n",
    "    \n",
    "    print(\"\\nSharpe Ratio (1981-2012):\", calculate_sharpe_ratio(HmL_rds))\n",
    "\n",
    "    \n",
    "    print(\"\\nRegression Results for 1981-2021\")\n",
    "    HmL_rds = get_regression_results(monthly_returns, last_period = pd.Timestamp(year=2021, month=12, day=31))\n",
    "     \n",
    "    print(\"\\nSharpe Ratio (1981-2021):\", calculate_sharpe_ratio(HmL_rds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all test\n",
    "\n",
    "On current machine, takes a little over an hour to run all tests due to iterative weight calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    '''\n",
    "    Main function to run all tests and results\n",
    "    '''\n",
    "    with warnings.catch_warnings():\n",
    "    \n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        \n",
    "        print(\"Gathering Data...\")\n",
    "        rd_firms, non_rd_firms, stocks = get_data()\n",
    "        \n",
    "        print(\"\\nCreating Equal Weighted Portfolio...\")\n",
    "        run_equal_portfolio(rd_firms, non_rd_firms, stocks)\n",
    "        \n",
    "        unknown_market_cap_zero_weight = True\n",
    "\n",
    "        print(\"\\n\\nCreating Value Weighted Portfolio...\")\n",
    "        run_value_portfolio(rd_firms, non_rd_firms, stocks, unknown_market_cap_zero_weight=unknown_market_cap_zero_weight)\n",
    "\n",
    "        print(\"\\n\\nCreating Value Weighted Portfolio without Top 1000...\")\n",
    "        run_value_portfolio(rd_firms, non_rd_firms, stocks, remove_top_1000_stocks=True, unknown_market_cap_zero_weight=unknown_market_cap_zero_weight)\n",
    "\n",
    "        print(\"Done.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering Data...\n",
      "Getting stock data\n",
      "Getting Fundamentals\n",
      "Splitting Firms into RD and non RD\n",
      "Calculating RD Capital / Market Cap\n",
      "Finding most recent report each year\n",
      "Removing outliers\n",
      "\n",
      "Creating Equal Weighted Portfolio...\n",
      "\n",
      "Average Monthly Return foe Equal Weighted Portfolio\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>H</th>\n",
       "      <th>Non R&amp;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full period</th>\n",
       "      <td>0.634</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.933</td>\n",
       "      <td>1.235</td>\n",
       "      <td>1.768</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre 2000</th>\n",
       "      <td>0.605</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.958</td>\n",
       "      <td>1.261</td>\n",
       "      <td>1.817</td>\n",
       "      <td>0.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post 2000</th>\n",
       "      <td>0.677</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.897</td>\n",
       "      <td>1.197</td>\n",
       "      <td>1.697</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full Through Dec 2021</th>\n",
       "      <td>0.713</td>\n",
       "      <td>0.831</td>\n",
       "      <td>1.050</td>\n",
       "      <td>1.276</td>\n",
       "      <td>1.709</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           L      2      3      4      H  Non R&D\n",
       "Full period            0.634  0.717  0.933  1.235  1.768    0.694\n",
       "Pre 2000               0.605  0.677  0.958  1.261  1.817    0.606\n",
       "Post 2000              0.677  0.774  0.897  1.197  1.697    0.820\n",
       "Full Through Dec 2021  0.713  0.831  1.050  1.276  1.709    0.736"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression Results for 1981-2012\n",
      "\n",
      "CAPM Regression\n",
      "alpha:  1.09\n",
      "t-stat:  4.243\n",
      "\n",
      "Fama French Regression Results\n",
      "alpha:  1.01\n",
      "t-stat:  3.892\n",
      "\n",
      "Sharpe Ratio (1981-2012): 0.792\n",
      "\n",
      "Regression Results for 1981-2021\n",
      "\n",
      "CAPM Regression\n",
      "alpha:  0.95\n",
      "t-stat:  4.257\n",
      "\n",
      "Fama French Regression Results\n",
      "alpha:  0.93\n",
      "t-stat:  4.142\n",
      "\n",
      "Sharpe Ratio (1981-2021): 0.709\n",
      "\n",
      "\n",
      "Creating Value Weighted Portfolio...\n",
      "\n",
      "Average Monthly Return for Value Weighted Portfolio\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>H</th>\n",
       "      <th>Non R&amp;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full period</th>\n",
       "      <td>0.475</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre 2000</th>\n",
       "      <td>0.678</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.901</td>\n",
       "      <td>1.246</td>\n",
       "      <td>1.226</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post 2000</th>\n",
       "      <td>0.186</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full Through Dec 2021</th>\n",
       "      <td>0.536</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.794</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           L      2      3      4      H  Non R&D\n",
       "Full period            0.475  0.625  0.633  0.923  0.835    0.593\n",
       "Pre 2000               0.678  1.020  0.901  1.246  1.226    0.764\n",
       "Post 2000              0.186  0.062  0.253  0.465  0.279    0.350\n",
       "Full Through Dec 2021  0.536  0.811  0.794  1.016  0.941    0.663"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression Results for 1981-2012\n",
      "\n",
      "CAPM Regression\n",
      "alpha:  0.32\n",
      "t-stat:  1.25\n",
      "\n",
      "Fama French Regression Results\n",
      "alpha:  0.2\n",
      "t-stat:  0.784\n",
      "\n",
      "Sharpe Ratio (1981-2012): 0.254\n",
      "\n",
      "Regression Results for 1981-2021\n",
      "\n",
      "CAPM Regression\n",
      "alpha:  0.37\n",
      "t-stat:  1.743\n",
      "\n",
      "Fama French Regression Results\n",
      "alpha:  0.33\n",
      "t-stat:  1.543\n",
      "\n",
      "Sharpe Ratio (1981-2021): 0.302\n",
      "\n",
      "\n",
      "Creating Value Weighted Portfolio without Top 1000...\n",
      "\n",
      "Average Monthly Return for Value Weighted Portfolio without Top 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>H</th>\n",
       "      <th>Non R&amp;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full period</th>\n",
       "      <td>0.444</td>\n",
       "      <td>0.752</td>\n",
       "      <td>1.069</td>\n",
       "      <td>0.844</td>\n",
       "      <td>1.680</td>\n",
       "      <td>0.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre 2000</th>\n",
       "      <td>0.356</td>\n",
       "      <td>0.809</td>\n",
       "      <td>1.247</td>\n",
       "      <td>0.932</td>\n",
       "      <td>1.660</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post 2000</th>\n",
       "      <td>0.558</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.731</td>\n",
       "      <td>1.706</td>\n",
       "      <td>0.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full Through Dec 2021</th>\n",
       "      <td>0.586</td>\n",
       "      <td>0.777</td>\n",
       "      <td>1.061</td>\n",
       "      <td>0.906</td>\n",
       "      <td>1.376</td>\n",
       "      <td>0.452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           L      2      3      4      H  Non R&D\n",
       "Full period            0.444  0.752  1.069  0.844  1.680    0.341\n",
       "Pre 2000               0.356  0.809  1.247  0.932  1.660    0.087\n",
       "Post 2000              0.558  0.679  0.838  0.731  1.706    0.668\n",
       "Full Through Dec 2021  0.586  0.777  1.061  0.906  1.376    0.452"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression Results for 1981-2012\n",
      "\n",
      "CAPM Regression\n",
      "alpha:  1.16\n",
      "t-stat:  3.186\n",
      "\n",
      "Fama French Regression Results\n",
      "alpha:  1.1\n",
      "t-stat:  2.993\n",
      "\n",
      "Sharpe Ratio (1981-2012): 0.627\n",
      "\n",
      "Regression Results for 1981-2021\n",
      "\n",
      "CAPM Regression\n",
      "alpha:  0.75\n",
      "t-stat:  2.363\n",
      "\n",
      "Fama French Regression Results\n",
      "alpha:  0.74\n",
      "t-stat:  2.327\n",
      "\n",
      "Sharpe Ratio (1981-2021): 0.405\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
